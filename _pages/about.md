---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a postdoctoral researcher at China Agricultural University (CAU), where I conduct interdisciplinary research on developing large language models (LLMs) for applications in animal science. Previously, from  2024-08  to July 2025-08, I worked as an LLM development engineer at CNIGC.

I received my Ph.D degree in Computer Science in 2024 from the Department of Computer Science and Technology at Beijing Institute of Technology (BIT), under the supervision of Professor [Dawei Song](https://scholar.google.com.hk/citations?user=PCTA8yAAAAAJ&hl=zh-CN). During my doctoral studies, my research primarily focused on the controllability of large language models (LLMs) in text generation, aiming to ensure that the generated content aligns with human expectations and values. Prior to that, I earned my master's and bachelor's degrees from Beijing Institute of Technology (BIT) and Harbin Engineering University (HEU) in 2020 and 2017, respectively.


I have been actively seeking collaborators for research and projects in the field of natural language processing (NLP), LLM and AI4Science.  If you're interested in my work, feel free to contact me at [zhanghanqing.fly@gmail.com](zhanghanqing.fly@gmail.com).


Interested research directions
======
 - Conduct fundamental research on the memory and reasoning capabilities of large language model (LLMs). Explore the relationship between memory and reasoning in LLMs, propose efficient methods to control these modes, and enhance the LLM's performance on memory- and reasoning-intensive tasks.
 
 - Identify efficient and essential methods for developing domain-specific LLMs, with a focus on animal sciences. My primary interests lie in the following sub-areas: (1) Data synthesis techniques using general-purpose LLMs to train domain-specific Small Language Models (SLMs)   (2) Mechanisms of interaction between domain-specific SLMs and general LLMs, aiming to adapt the capabilities of general models to specialized domains at minimal cost. (3) Develop LLM agents tailored for domain-specific AI applications. For example, create an intelligent assessment agent to address challenges in livestock farming, offering management insights and optimization suggestions for the farm.
   
 - I am exploring research at the intersection of AI and the life sciences, with a focus on applying large language model (LLM) technology to biological and medical domains. For example, my work includes developing LLM-based models for the early warning and diagnosis of animal diseases, leveraging physiological indicators and genetic sequences.


Selected Publications
======
- **Hanqing Zhang**，et al. Emotion-Aware LLM Adaptation for Empathetic Dialogue Generation[J]. IEEE Transactions on Audio, Speech and Language Processing, 2025. (TASLP)
- **Hanqing Zhang**, et al. Controllable Text Generation with Residual Memory Transformer[C].  In findings of Proceedings of the Association for Computational Linguistics: ACL2024, pages 1048–1066, Bangkok, Thailand. Association for Computational Linguistics. (ACL 2024)
- **Hanqing Zhang**, Haolin Song, Shaoyu Li, Ming Zhou, Dawei Song. A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models[J]. ACM Computing Surveys, 2023, 56(3). (CSUR)
- **Hanqing Zhang** and Song Dawei. DisCup: Discriminator Cooperative Unlikelihood Prompt Tuning for Controllable Text Generation[C]. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Abu Dhabi, United Arab Emirates: Association for Computational Linguistics, 2022: 3392-3406. (EMNLP 2022)
- **Hanqing Zhang** and Song Dawei. Towards Contrastive Context-aware Conversational Emotion Recognition[J]. IEEE Transactions on Affective Computing, 2022, 13(4): 1879-1891. (TAFFC)
- Zhuosheng Zhang, **Hanqing Zhang**, Chen K, et al. Mengzi: Towards lightweight yet ingenious pre-trained models for chinese[J]. arXiv preprint arXiv:2110.06696, 2021. (Technical Report)
- **Hanqing Zhang**, et al. An Efficient Android Malware Detection System Based on Method-Level Behavioral Semantic Analysis[J].IEEE ACCESS,2019, 7: 69246-69256. （Highly Cited Paper）



Hobbies
======

- Favorite Foods: Coca-Cola, salmon, Hunan cuisine, and Sichuan cuisine
- Hobbies: Fishing, traveling, watching movies, swimming, playing badminton, and playing mobile games such as League of Legends and Honor of Kings


Honors and Awards
======

- Doctoral Student Special Scholarship (2023);
- Beijing Outstanding Graduate (2020);
- Beijing Institute of Technology Outstanding Master's Thesis (2020),
- Beijing Institute of Technology Outstanding Graduate (2020);
- Beijing Institute of Technology Graduate National Scholarship (2019);
- China Graduate Electronics Design Competition: Android System Service Efficient Fuzz Testing Platform – Provincial Second Prize（2019);
- Nanjing Global Artificial Intelligence Application Competition: Prediction of Highway Trunk Logistics Regional Supply-Demand Relationships – Global Data Mining Competition (Top 1), Awarded 50,000 RMB（2018）
- National TI Cup Undergraduate Electronic Design Competition: Pulse Signal Parameter Measurement Instrument – Provincial Second Prize（2016）
- RoboCup National Robotics Competition: Underwater Patrol Robot – National Special Prize （2015）
- National Renesas Cup Undergraduate Electronic Design Competition: Digital Frequency Meter – Provincial Second Prize（2015）





