---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently affiliated with China Agricultural University, where I am engaged in interdisciplinary research on building large language models (LLMs) for applications in animal science. 

I received my Ph.D. in 2024 from the Department of Computer Science and Technology at Beijing Institute of Technology, under the supervision of Professor [Dawei Song](https://scholar.google.com.hk/citations?user=PCTA8yAAAAAJ&hl=zh-CN). During my doctoral studies, my research primarily focused on the controllability of large language models in text generation, aiming to ensure that the generated content aligns with human expectations and values. Prior to that, I earned my master's and bachelor's degrees from Beijing Institute of Technology and Harbin Engineering University in 2020 and 2017, respectively.


If you're interested in my work, feel free to contact me at [zhanghanqing.fly@gmail.com](zhanghanqing.fly@gmail.com).


Interested research directions
======
 -- Explore the relationship between memory and reasoning in LLMs, identify efficient methods to control these modes, and enhance the LLM's performance on memory- and reasoning-intensive tasks.
 
 -- Identify efficient and essential methods for developing domain-specific LLMs, with a focus on animal sciences. My primary interests lie in the following sub-areas: (1) Data synthesis techniques using general-purpose LLMs to train domain-specific Small Language Models (SLMs)   (2) Mechanisms of interaction between domain-specific SLMs and general LLMs, aiming to adapt the capabilities of general models to specialized domains at minimal cost.



Selected Publications
======
-- Hanqing Zhang, et al. Controllable Text Generation with Residual Memory Transformer[C].  In findings of Proceedings of the Association for Computational Linguistics: ACL2024, pages 1048–1066, Bangkok, Thailand. Association for Computational Linguistics. (ACL 2024)

-- Hanqing Zhang and Song Dawei. DisCup: Discriminator Cooperative Unlikelihood Prompt Tuning for Controllable Text Generation[C]. Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Abu Dhabi, United Arab Emirates: Association for Computational Linguistics, 2022: 3392-3406. (EMNLP 2022)

-- Hanqing Zhang, Haolin Song, Shaoyu Li, Ming Zhou, Dawei Song. A Survey of Controllable Text Generation Using Transformer-based Pre-trained Language Models[J]. ACM Computing Surveys, 2023, 56(3). (CSUR)

-- Hanqing Zhang and Song Dawei. Towards Contrastive Context-aware Conversational Emotion Recognition[J]. IEEE Transactions on Affective Computing, 2022, 13(4): 1879-1891. (TAFFC)

-- Hanqing Zhang，et al. Emotion-Aware LLM Adaptation for Empathetic Dialogue Generation[J]. IEEE Transactions on Audio, Speech and Language Processing.  (Major Revision) (TASLP)

-- Hanqing Zhang, et al. An Efficient Android Malware Detection System Based on Method-Level Behavioral Semantic Analysis[J].IEEE ACCESS,2019, 7: 69246-69256.


